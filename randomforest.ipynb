{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_RY1d_g3qXaj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d6e1539"
      },
      "source": [
        "# Task\n",
        "Write a random forest function from scratch in Python, including implementations for decision trees, bagging, and random subspace, and provide a prediction function and evaluation method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5792181b"
      },
      "source": [
        "## Implement a decision tree\n",
        "\n",
        "### Subtask:\n",
        "Create a function or class for a basic decision tree that can handle splitting data based on features and making predictions. This will be the building block of the random forest.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2300ac1"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement a class for a decision tree that includes methods for calculating Gini impurity, finding the best split, building the tree recursively, and making predictions. This addresses all parts of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efdb9406"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.tree = None\n",
        "\n",
        "    def _gini_impurity(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        proportions = np.bincount(y) / len(y)\n",
        "        return 1.0 - np.sum(proportions**2)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_gini = float('inf')\n",
        "        best_feature_index = None\n",
        "        best_threshold = None\n",
        "\n",
        "        for feature_index in range(n):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
        "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                gini_left = self._gini_impurity(y[left_indices])\n",
        "                gini_right = self._gini_impurity(y[right_indices])\n",
        "                gini = (len(left_indices) * gini_left + len(right_indices) * gini_right) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature_index = feature_index\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature_index, best_threshold\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        if depth == self.max_depth or len(y) < self.min_samples_split or len(np.unique(y)) == 1:\n",
        "            leaf_value = Counter(y).most_common(1)[0][0]\n",
        "            return {'leaf': leaf_value}\n",
        "\n",
        "        feature_index, threshold = self._best_split(X, y)\n",
        "\n",
        "        if feature_index is None:\n",
        "            leaf_value = Counter(y).most_common(1)[0][0]\n",
        "            return {'leaf': leaf_value}\n",
        "\n",
        "        left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
        "        right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return {'feature_index': feature_index, 'threshold': threshold,\n",
        "                'left': left_subtree, 'right': right_subtree}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, 0)\n",
        "\n",
        "    def _predict_single(self, x, tree):\n",
        "        if 'leaf' in tree:\n",
        "            return tree['leaf']\n",
        "\n",
        "        feature_index = tree['feature_index']\n",
        "        threshold = tree['threshold']\n",
        "\n",
        "        if x[feature_index] <= threshold:\n",
        "            return self._predict_single(x, tree['left'])\n",
        "        else:\n",
        "            return self._predict_single(x, tree['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict_single(x, self.tree) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Example usage (optional - for testing the class)\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.datasets import load_iris\n",
        "#\n",
        "# iris = load_iris()\n",
        "# X, y = iris.data, iris.target\n",
        "#\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#\n",
        "# tree = DecisionTree(max_depth=3)\n",
        "# tree.fit(X_train, y_train)\n",
        "#\n",
        "# predictions = tree.predict(X_test)\n",
        "# print(predictions)\n",
        "# print(y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f79aa55b"
      },
      "source": [
        "## Implement bagging (bootstrap aggregating)\n",
        "\n",
        "### Subtask:\n",
        "Create a function to generate multiple bootstrap samples of the training data. Each sample will be used to train a separate decision tree.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc3144e0"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `bootstrap_sample` function to generate bootstrap samples as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f55fa70"
      },
      "source": [
        "def bootstrap_sample(X, y):\n",
        "    \"\"\"Generates a single bootstrap sample of the training data.\n",
        "\n",
        "    Args:\n",
        "        X: The training features (numpy array).\n",
        "        y: The training labels (numpy array).\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the bootstrap sample of features and labels (X_sample, y_sample).\n",
        "    \"\"\"\n",
        "    n_samples = len(X)\n",
        "    indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "    X_sample = X[indices]\n",
        "    y_sample = y[indices]\n",
        "    return X_sample, y_sample\n",
        "\n",
        "# Example usage (optional - for testing the function)\n",
        "# from sklearn.datasets import load_iris\n",
        "#\n",
        "# iris = load_iris()\n",
        "# X, y = iris.data, iris.target\n",
        "#\n",
        "# X_sample, y_sample = bootstrap_sample(X, y)\n",
        "# print(\"Original data shape:\", X.shape, y.shape)\n",
        "# print(\"Bootstrap sample shape:\", X_sample.shape, y_sample.shape)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fc65d76"
      },
      "source": [
        "## Implement random subspace\n",
        "\n",
        "### Subtask:\n",
        "Modify the decision tree implementation to randomly select a subset of features at each split point. This adds more randomness to the forest and helps prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "901a214a"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `DecisionTree` class to include the `max_features` parameter and update the `_best_split` method to randomly select a subset of features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2359a920"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, max_features=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_features = max_features\n",
        "        self.tree = None\n",
        "\n",
        "    def _gini_impurity(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        proportions = np.bincount(y) / len(y)\n",
        "        return 1.0 - np.sum(proportions**2)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_gini = float('inf')\n",
        "        best_feature_index = None\n",
        "        best_threshold = None\n",
        "\n",
        "        # Determine the number of features to consider\n",
        "        if self.max_features is None:\n",
        "            num_features_to_consider = n\n",
        "        elif isinstance(self.max_features, int):\n",
        "            num_features_to_consider = min(self.max_features, n)\n",
        "        elif isinstance(self.max_features, float):\n",
        "            num_features_to_consider = int(self.max_features * n)\n",
        "        else:\n",
        "            num_features_to_consider = n # Default to all features if max_features is invalid\n",
        "\n",
        "        # Randomly select a subset of features\n",
        "        feature_indices_to_consider = np.random.choice(n, num_features_to_consider, replace=False)\n",
        "\n",
        "\n",
        "        for feature_index in feature_indices_to_consider:\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
        "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
        "\n",
        "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
        "                    continue\n",
        "\n",
        "                gini_left = self._gini_impurity(y[left_indices])\n",
        "                gini_right = self._gini_impurity(y[right_indices])\n",
        "                gini = (len(left_indices) * gini_left + len(right_indices) * gini_right) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature_index = feature_index\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature_index, best_threshold\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        if depth == self.max_depth or len(y) < self.min_samples_split or len(np.unique(y)) == 1:\n",
        "            leaf_value = Counter(y).most_common(1)[0][0]\n",
        "            return {'leaf': leaf_value}\n",
        "\n",
        "        feature_index, threshold = self._best_split(X, y)\n",
        "\n",
        "        if feature_index is None:\n",
        "            leaf_value = Counter(y).most_common(1)[0][0]\n",
        "            return {'leaf': leaf_value}\n",
        "\n",
        "        left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
        "        right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return {'feature_index': feature_index, 'threshold': threshold,\n",
        "                'left': left_subtree, 'right': right_subtree}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, 0)\n",
        "\n",
        "    def _predict_single(self, x, tree):\n",
        "        if 'leaf' in tree:\n",
        "            return tree['leaf']\n",
        "\n",
        "        feature_index = tree['feature_index']\n",
        "        threshold = tree['threshold']\n",
        "\n",
        "        if x[feature_index] <= threshold:\n",
        "            return self._predict_single(x, tree['left'])\n",
        "        else:\n",
        "            return self._predict_single(x, tree['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict_single(x, self.tree) for x in X]\n",
        "        return np.array(predictions)"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}